# ==========================================
# 3. æ ¸å¿ƒåˆ†æå™¨ (ç”ŸæˆæŠ¥å‘Šé€»è¾‘)
# ==========================================
class ModelInsightGenerator:
    def __init__(self, old_model, new_model, vocab_mapper):
        self.old_model = old_model
        self.new_model = new_model
        self.vocab = vocab_mapper
        
    def calculate_metrics(self, df):
        """å®è§‚ï¼šè®¡ç®— AUC å’Œ Loss"""
        y_true = df['label'].values
        # è·å–æ¨¡æ‹Ÿåˆ†æ•°
        y_pred_old = self.old_model.predict_mock(df).numpy()
        y_pred_new = self.new_model.predict_mock(df).numpy()
        
        metrics = {
            'old_auc': roc_auc_score(y_true, y_pred_old),
            'new_auc': roc_auc_score(y_true, y_pred_new),
            'old_loss': log_loss(y_true, y_pred_old),
            'new_loss': log_loss(y_true, y_pred_new)
        }
        return metrics

    def get_embedding_shifts(self, top_k=5):
        """ä¸­è§‚ï¼šè®¡ç®— Embedding å˜åŠ¨"""
        shifts = []
        old_emb = self.old_model.embeddings['brand_name'].weight.data.numpy()
        new_emb = self.new_model.embeddings['brand_name'].weight.data.numpy()
        
        for token, idx in self.vocab.token2id.items():
            if idx < len(old_emb):
                # è®¡ç®—æ¬§æ°è·ç¦»
                diff = np.linalg.norm(old_emb[idx] - new_emb[idx])
                shifts.append((token, diff))
                
        # æŒ‰å˜åŠ¨å¹…åº¦é™åº
        shifts.sort(key=lambda x: x[1], reverse=True)
        return shifts[:top_k]

    def find_repaired_cases(self, df, top_k=3):
        """å¾®è§‚ï¼šæŒ–æ˜è¢«æ–°æ¨¡å‹'æ‹¯æ•‘'çš„æ¡ˆä¾‹"""
        repaired = []
        
        y_pred_old = self.old_model.predict_mock(df).numpy()
        y_pred_new = self.new_model.predict_mock(df).numpy()
        
        for i, row in df.iterrows():
            # åªçœ‹æ­£æ ·æœ¬ (label=1)
            if row['label'] == 0: continue
            
            s_old = y_pred_old[i]
            s_new = y_pred_new[i]
            
            # é€»è¾‘ï¼šæ—§çš„åˆ†ä½ï¼Œæ–°çš„åˆ†é«˜
            if s_old < 0.5 and s_new > 0.8:
                repaired.append({
                    'brand': row['brand_name'],
                    'fault': row['fault_desc'],
                    'dist': row['distance_km'],
                    'old': s_old,
                    'new': s_new,
                    'diff': s_new - s_old
                })
        
        repaired.sort(key=lambda x: x['diff'], reverse=True)
        return repaired[:top_k]

# ==========================================
# 4. ç”Ÿæˆ Markdown æŠ¥å‘Šæ–‡æœ¬
# ==========================================
def render_markdown(metrics, shifts, cases):
    # è®¡ç®—æ¶¨è·Œç¬¦å·
    auc_diff = metrics['new_auc'] - metrics['old_auc']
    auc_sign = "ğŸ”º" if auc_diff > 0 else "ğŸ”»"
    
    loss_diff = metrics['new_loss'] - metrics['old_loss']
    loss_sign = "ğŸ”»" if loss_diff < 0 else "ğŸ”º" # Loss è¶Šå°è¶Šå¥½
    
    md = f"""
# ğŸš€ æ¯æ—¥æ¨¡å‹è¿›åŒ–æ—¥æŠ¥ (2024-05-20)

## 1. ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡çœ‹æ¿ (The Scoreboard)
> ä»Šæ—¥æ¨¡å‹åœ¨éªŒè¯é›†è¡¨ç° **ç¨³ä¸­æœ‰å‡**ï¼ŒæˆåŠŸé€šè¿‡ä¸Šçº¿æ ‡å‡†ã€‚

| æ ¸å¿ƒæŒ‡æ ‡ | æ—§æ¨¡å‹ (Baseline) | æ–°æ¨¡å‹ (Current) | å˜åŒ–å¹…åº¦ | çŠ¶æ€ |
| :--- | :--- | :--- | :--- | :--- |
| **AUC (æ’åºèƒ½åŠ›)** | {metrics['old_auc']:.4f} | **{metrics['new_auc']:.4f}** | {auc_sign} {abs(auc_diff)*100:.2f}% | âœ… è¾¾æ ‡ |
| **LogLoss (å‡†ç¡®åº¦)** | {metrics['old_loss']:.4f} | **{metrics['new_loss']:.4f}** | {loss_sign} {abs(loss_diff):.4f} | âœ… è¾¾æ ‡ |

---

## 2. ğŸ§  çŸ¥è¯†å‘ç°ï¼šæ¨¡å‹ä»Šå¤©â€œå­¦åˆ°äº†â€ä»€ä¹ˆï¼Ÿ(Knowledge Discovery)
é€šè¿‡åˆ†æ Embedding å‘é‡ç©ºé—´çš„ä½ç§»ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹å¯¹ä»¥ä¸‹ **5 ä¸ªå“ç‰Œ** çš„è®¤çŸ¥å‘ç”Ÿäº†å‰§å˜ã€‚
*è¿™é€šå¸¸æ„å‘³ç€ï¼šæœ‰äº†æ–°çš„ç§¯å‹æ•°æ®è¾“å…¥ï¼Œæˆ–è€… BGE è¯­ä¹‰çº æ­£äº†ä¹‹å‰çš„éšæœºå‚æ•°ã€‚*

| å“ç‰Œåç§° | è®¤çŸ¥è°ƒæ•´å¹…åº¦ (Embedding Shift) | ä¸šåŠ¡è§£è¯» |
| :--- | :--- | :--- |
"""
    for brand, shift in shifts:
        interp = "å¸¸è§„å‚æ•°å¾®è°ƒ"
        if shift > 1.0: interp = "ğŸ”¥ **é‡å¤§è®¤çŸ¥é‡æ„ (æ–°çŸ¥è¯†æ³¨å…¥)**"
        elif shift > 0.5: interp = "âš ï¸ æ˜¾è‘—å‚æ•°è°ƒæ•´"
        md += f"| **{brand}** | `{shift:.4f}` | {interp} |\n"

    md += """
---

## 3. âœ¨ äº®ç‚¹æ¡ˆä¾‹ï¼šBad Case ä¿®å¤å±•ç¤º (The "Save" Cases)
ä»¥ä¸‹æ˜¯ **å®¢æˆ·çœŸå®å»äº†è¯¥åº— (Label=1)**ï¼Œæ—§æ¨¡å‹è®¤ä¸º**ä¸åŒ¹é… (Score<0.5)**ï¼Œä½†æ–°æ¨¡å‹**ç²¾å‡†å‘½ä¸­ (Score>0.8)** çš„å…¸å‹æ¡ˆä¾‹ã€‚

"""
    for i, case in enumerate(cases):
        md += f"""### ğŸ¯ æ¡ˆä¾‹ {i+1}: {case['brand']} ç»´ä¿®åŒ¹é…
- **åœºæ™¯ç‰¹å¾**:
  - æ•…éšœæè¿°: `"{case['fault']}"`
  - å¯¼èˆªè·ç¦»: `{case['dist']} km`
- **æ¨¡å‹æ‰“åˆ†å¯¹æ¯”**:
  - ğŸ”´ æ—§æ¨¡å‹: `{case['old']:.2f}` (åˆ¤æ–­å¤±è¯¯ï¼šè®¤ä¸ºä¸é¡ºè·¯æˆ–ä¸åŒ¹é…)
  - ğŸŸ¢ **æ–°æ¨¡å‹**: **`{case['new']:.2f}`** (åˆ¤æ–­æ­£ç¡®ï¼šå¼ºçƒˆæ¨è)
- **å½’å› åˆ†æ**: æ–°æ¨¡å‹æˆåŠŸæ•æ‰åˆ°äº† **{case['brand']}** ä¸è¯¥ç½‘ç‚¹èµ„è´¨çš„å¼ºå…³è”ï¼Œä¿®æ­£äº†æ—§æ¨¡å‹çš„åè§ã€‚

"""
    return md

# ==========================================
# 5. ä¸»æ‰§è¡Œé€»è¾‘
# ==========================================
if __name__ == "__main__":
    # 1. å‡†å¤‡ç¯å¢ƒ
    vocab = MockVocabMapper()
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ (æ¨¡æ‹Ÿ Old å’Œ New)
    old_model = MockDeepFM(vocab, model_version='old')
    new_model = MockDeepFM(vocab, model_version='new')
    
    # 3. ç”Ÿæˆæ•°æ® (å«é¢„åŸ‹çš„ä¿®å¤æ¡ˆä¾‹)
    val_df = generate_demo_data(num_samples=100)
    
    # 4. æ‰§è¡Œåˆ†æ
    analyzer = ModelInsightGenerator(old_model, new_model, vocab)
    
    metrics = analyzer.calculate_metrics(val_df)
    shifts = analyzer.get_embedding_shifts()
    cases = analyzer.find_repaired_cases(val_df)
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    report_content = render_markdown(metrics, shifts, cases)
    
    print(report_content)
